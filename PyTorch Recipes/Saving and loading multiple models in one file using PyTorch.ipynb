{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bf0774",
   "metadata": {},
   "source": [
    "여러 모델을 저장하고 불러오는 것은 이전에 학습했던 모델들을 재사용하는데 도움이 된다\n",
    "<br><br>\n",
    "\n",
    "## 개요\n",
    "GAN이나 시퀀스-투-시퀀스(sequence-to-sequence model), 앙상블 모델(ensemble of models)과 같이 여러 ```torch.nn.Modules``` 로 구성된 모델을 저장할 때는 각 모델의 state_dict와 해당 옵티마이저의 dictionary를 저장해야한다. 또한, 학습을 재개하는데 필요한 다른 항목들을 dictionary에 추가할 수 있다. 모델들을 불러올 때에는, 먼저 모델들과 옵티마이저를 초기화하고, ```torch.load()```를 사용하여 dictionary를 불러온다. 이후 원하는대로 저장한 항목들을 dictionary에 조회하여 접근할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2206e205",
   "metadata": {},
   "source": [
    "## 단계\n",
    "1. 데이터를 불러올 때 필요한 라이브러리들 불러오기\n",
    "2. 신경망을 구성하고 초기화하기\n",
    "3. 옵티마이저 초기화하기\n",
    "4. 여러 모델들 저장하기\n",
    "5. 여러 모델들 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72990d2a",
   "metadata": {},
   "source": [
    "### 1. 데이터를 불러올 때 필요한 라이브러리들 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1262b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce8f28",
   "metadata": {},
   "source": [
    "### 2. 신경망을 구성하고 초기화하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5ad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "netA = Net()\n",
    "netB = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220fac9f",
   "metadata": {},
   "source": [
    "### 3. 옵티마이저 초기화하기\n",
    "생성한 모델들을 각각에 모멘텀을 갖는 SGD를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bed03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerA = optim.SGD(netA.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerB = optim.SGD(netB.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd45df4",
   "metadata": {},
   "source": [
    "### 4. 여러 모델들 저장하기\n",
    "관련된 모든 정보들을 모아서 사전을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ce14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장할 경로 지정\n",
    "PATH = \"model.pt\"\n",
    "\n",
    "torch.save({\n",
    "    'modelA_state_dict':netA.state_dict(),\n",
    "    'modelB_state_dict':netB.state_dict(),\n",
    "    'optimizerA_state_dict':optimizerA.state_dict(),\n",
    "    'optimizerB_state_dict':optimizerB.state_dict(),\n",
    "    }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4497241",
   "metadata": {},
   "source": [
    "### 5. 여러 모델들 불러오기\n",
    "먼저 모델과 옵티마이저를 초기화한 뒤, dictionary를 불러와야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f8d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA = Net()\n",
    "modelB = Net()\n",
    "optimModelA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)\n",
    "optimModelB = optim.SGD(modelB.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# -- 또는 --\n",
    "modelA.train()\n",
    "modelB.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7885ad2",
   "metadata": {},
   "source": [
    "inference를 실행하기 전에 ```model.eval()```을 호출하여 드롭아웃(dropout)과 배치 정규화 층(batch normalization layer)을 evaluation mode로 바꿔야한다. <br>\n",
    "만약 학습을 계속하길 원한다면 ```model.train()```을 호출하여 이 층(layer)들이 학습 모드인지 확인해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b6c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
