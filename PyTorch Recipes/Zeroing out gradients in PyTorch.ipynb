{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49d9a63",
   "metadata": {},
   "source": [
    "신경망을 구축할 때는 변화도를 0으로 만들어 주는 것이 좋다. 기본적으로 ```.backward()```를 호출할 때마다 변화도가 버퍼에 쌓이기 때문이다. (덮어쓰지 않는 다는 의미)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4071672",
   "metadata": {},
   "source": [
    "## 개요\n",
    "신경망을 학습시킬 때, 경사 하강법을 거쳐 모델 정확도를 높일 수 있다. 경사 하강법은 간단히 설명해 모델의 가중치와 편향을 약간씩 수정하면서 손실(또는 오류)를 최소화하는 과정이다.<br><br>\n",
    "```torch.Tensor```는 PyTorch의 핵심이 되는 클래스다. 텐서를 생성할 때 ```.requires_grad```속성을 ```True```로 설정하면, 텐서에 가해진 모든 연산을 추척한다. 뒤따르는 모든 역전파 단계에서도, 이 텐서의 변화도는 ```.grad``` 속성에 누적된다. 모든 변화도의 축적 또는 합은 손실 텐서에서 ```.backward()```를 호출할 때 계산된다. <br><br>\n",
    "텐서의 변화도를 0으로 만들어 주어야 하는 경우도 있다. 예를 들어 학습 과정 반복문을 시작할 때, 누적되는 변화도를 정확하게 추적하기 위해서는 변화도를 우선 0으로 만들어줘야한다. 이 레시피에서는 PyTorch 라이브러리를 사용하여 변화도를 0으로 만드는 방법을 배운다. PyTorch에 내장된 ```CIFAR10```데이터셋에 대하여 신경망을 훈련시키는 과정을 통해 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f30152",
   "metadata": {},
   "source": [
    "## 설정\n",
    "이 레시피에는 데이터를 학습시키는 내용이 포함되어 있어 런타임을 GPU 또는 TPU로 전환하는 것이 좋다.\n",
    "시작하기에 앞서, ```torch```와 ```torchvision```패키지가 없다면 설치한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91f7e06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (1.9.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (from torch) (3.10.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cde803d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (from torchvision) (1.20.2)\n",
      "Requirement already satisfied: torch in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (from torchvision) (1.9.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages (from torch->torchvision) (3.10.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdea5e",
   "metadata": {},
   "source": [
    "## 단계\n",
    "1단계부터 4단계까지는 학습을 위한 데이터와 신경망을 준비하며, 5단계에서 변화도를 0으로 만들어 준다.\n",
    "1. 데이터를 불러오기 위해 필요한 라이브러리 import\n",
    "2. 데이터셋 불러오고 정규화\n",
    "3. 신경망 구축\n",
    "4. 손실 함수 정의\n",
    "5. 신경망을 학습시킬 때 변화도 0으로 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be537d",
   "metadata": {},
   "source": [
    "### 1. 데이터를 불러오기 위해 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40b319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8143821",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 불러오고 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd22ab4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "5.3%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "7.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "10.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "18.3%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "34.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "40.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "43.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29491e",
   "metadata": {},
   "source": [
    "### 3. 신경망 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18531cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee2427",
   "metadata": {},
   "source": [
    "### 4. 손실 함수와 옵티마이저 정의\n",
    "분류를 위한 Cross-Entropy 손실 함수와 모멘텀을 설정한 SGD 옵티마이저를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c824f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749afa9",
   "metadata": {},
   "source": [
    "### 5. 신경망을 학습시키는 동안 변화도를 0으로 만들기\n",
    "여기서 할 일은 데이터 이터레이터를 순회하면서, 신경망에 입력을 주고 최적화하는 것이다.<br>\n",
    "데이터의 엔티티 각각의 변화도를 0으로 만들어주는 것에 유의. 신경망을 학습시킬 때 불필요한 정보를 추적하지 않도록 하기 위함이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3dd760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongjin-u/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459064158/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.184\n",
      "[1,  4000] loss: 1.801\n",
      "[1,  6000] loss: 1.655\n",
      "[1,  8000] loss: 1.569\n",
      "[1, 10000] loss: 1.497\n",
      "[1, 12000] loss: 1.459\n",
      "[2,  2000] loss: 1.386\n",
      "[2,  4000] loss: 1.337\n",
      "[2,  6000] loss: 1.320\n",
      "[2,  8000] loss: 1.311\n",
      "[2, 10000] loss: 1.292\n",
      "[2, 12000] loss: 1.279\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546951d",
   "metadata": {},
   "source": [
    "```model.zero_grad()```를 사용해도 변화도를 0으로 만들 수 있다. 이는 옵티마이저에 모든 모델 파라미터가 포함되는 한 ```optimizer.zero_grad()```를 사용하는 것과 동일하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378100d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
